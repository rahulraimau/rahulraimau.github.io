{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "# Molecular Properties Prediction: Analysis, Modeling, and Visualization\n",
    "\n",
    "This notebook predicts molecular properties (Tg, FFV, Tc, Density, Rg) for SMILES strings using the `train.csv` dataset. It includes:\n",
    "- Data loading and preprocessing\n",
    "- Featurization using RDKit\n",
    "- Correlation analysis with visualizations\n",
    "- Random Forest model training and evaluation\n",
    "- Predictions for test SMILES\n",
    "- Generation of model report and submission file\n",
    "\n",
    "Outputs:\n",
    "- `model_report.csv`: Model performance metrics (R2, RMSE)\n",
    "- `correlation_matrix.png`, `scatter_{descriptor}_vs_{property}.png`: Visualization images\n",
    "- `submission.csv`: Predicted properties for test SMILES\n",
    "\n",
    "**Note**: Ensure `train.csv` is in the working directory. In Kaggle, use `/kaggle/input/` paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - rdkit\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning  libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE\n",
      "\n",
      "LibMambaUnsatisfiableError: Encountered problems while solving:\n",
      "  - nothing provides numpy 1.10.* needed by rdkit-2015.09.2-np110py27_0\n",
      "\n",
      "Could not solve for environment specs\n",
      "The following packages are incompatible\n",
      "\\u251c\\u2500 pin-1 is installable and it requires\n",
      "\\u2502  \\u2514\\u2500 python 3.12.* , which can be installed;\n",
      "\\u2514\\u2500 rdkit is not installable because there are no viable options\n",
      "   \\u251c\\u2500 rdkit [2014.09.2|2015.03.1|...|2017.09.3.0] would require\n",
      "   \\u2502  \\u2514\\u2500 python [2.7* |>=2.7,<2.8.0a0 ], which conflicts with any installable versions previously reported;\n",
      "   \\u251c\\u2500 rdkit [2015.09.2|2016.03.1] would require\n",
      "   \\u2502  \\u2514\\u2500 numpy 1.10.* , which does not exist (perhaps a missing channel);\n",
      "   \\u251c\\u2500 rdkit [2016.03.1|2016.09.2|...|2018.03.1.1] would require\n",
      "   \\u2502  \\u2514\\u2500 python [3.5* |>=3.5,<3.6.0a0 ], which conflicts with any installable versions previously reported;\n",
      "   \\u251c\\u2500 rdkit [2017.03.1|2017.03.2|...|2020.09.1.0] would require\n",
      "   \\u2502  \\u2514\\u2500 python [3.6* |>=3.6,<3.7.0a0 ], which conflicts with any installable versions previously reported;\n",
      "   \\u2514\\u2500 rdkit [2018.09.2.0|2018.09.3.0|...|2020.09.1.0] would require\n",
      "      \\u2514\\u2500 python >=3.7,<3.8.0a0 , which conflicts with any installable versions previously reported.\n",
      "\n",
      "Pins seem to be involved in the conflict. Currently pinned specs:\n",
      " - python 3.12.* (labeled as 'pin-1')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c rdkit rdkit -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: rdkit in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (2025.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from rdkit) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from rdkit) (11.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~yproj (C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~yproj (C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~yproj (C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~yproj (C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~yproj (C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Install RDKit if needed (uncomment in Kaggle)\n",
    "# !conda install -c rdkit rdkit -y\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (7973, 7)\n",
      "Test dataset shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87817</td>\n",
       "      <td>*CC(*)c1ccccc1C(=O)OCCCCCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374645</td>\n",
       "      <td>0.205667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106919</td>\n",
       "      <td>*Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388772</td>\n",
       "      <td>*Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>519416</td>\n",
       "      <td>*Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539187</td>\n",
       "      <td>*Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             SMILES  Tg       FFV  \\\n",
       "0   87817                         *CC(*)c1ccccc1C(=O)OCCCCCC NaN  0.374645   \n",
       "1  106919  *Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5... NaN  0.370410   \n",
       "2  388772  *Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(... NaN  0.378860   \n",
       "3  519416  *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)... NaN  0.387324   \n",
       "4  539187  *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N... NaN  0.355470   \n",
       "\n",
       "         Tc  Density  Rg  \n",
       "0  0.205667      NaN NaN  \n",
       "1       NaN      NaN NaN  \n",
       "2       NaN      NaN NaN  \n",
       "3       NaN      NaN NaN  \n",
       "4       NaN      NaN NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "try:\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    train_df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\neurips-open-polymer-prediction-2025\\train.csv\")\n",
    "\n",
    "# Define test SMILES\n",
    "test_data = [\n",
    "    {\"id\": 1109053969, \"SMILES\": \"*Oc1ccc(C=NN=Cc2ccc(Oc3ccc(C(c4ccc(*)cc4)(C(F)(F)F)C(F)(F)F)cc3)cc2)cc1\"},\n",
    "    {\"id\": 1422188626, \"SMILES\": \"*Oc1ccc(C(C)(C)c2ccc(Oc3ccc(C(=O)c4cccc(C(=O)c5ccc(*)cc5)cc3)cc2)cc1\"},\n",
    "    {\"id\": 2032016830, \"SMILES\": \"*c1cccc(OCCCCCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6c5C(=O)N(*)C6=O)cc4C3=O)c2)c1\"}\n",
    "]\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Verify data\n",
    "print('Train dataset shape:', train_df.shape)\n",
    "print('Test dataset shape:', test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['MolWt', 'TPSA', 'NumRotatableBonds', 'NumHeavyAtoms'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m test_df \u001b[38;5;241m=\u001b[39m test_df[test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescriptors\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Extract numerical descriptors\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m train_descriptors \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDescriptors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMolWt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTPSA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNumRotatableBonds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNumHeavyAtoms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     27\u001b[0m test_descriptors \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mlist\u001b[39m(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescriptors\u001b[39m\u001b[38;5;124m'\u001b[39m]))[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMolWt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPSA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumRotatableBonds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumHeavyAtoms\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Extract fingerprints\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['MolWt', 'TPSA', 'NumRotatableBonds', 'NumHeavyAtoms'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Featurization function\n",
    "def compute_descriptors(smiles):\n",
    "    smiles = smiles.replace('*', 'H')\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    descriptors = {\n",
    "        'MolWt': Descriptors.MolWt(mol),\n",
    "        'TPSA': Descriptors.TPSA(mol),\n",
    "        'NumRotatableBonds': Descriptors.NumRotatableBonds(mol),\n",
    "        'NumHeavyAtoms': Descriptors.HeavyAtomCount(mol)\n",
    "    }\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    descriptors['Fingerprint'] = np.array(fp)\n",
    "    return descriptors\n",
    "\n",
    "# Apply featurization\n",
    "train_df['Descriptors'] = train_df['SMILES'].apply(compute_descriptors)\n",
    "test_df['Descriptors'] = test_df['SMILES'].apply(compute_descriptors)\n",
    "\n",
    "# Remove invalid SMILES\n",
    "train_df = train_df[train_df['Descriptors'].notnull()]\n",
    "test_df = test_df[test_df['Descriptors'].notnull()]\n",
    "\n",
    "# Extract numerical descriptors\n",
    "train_descriptors = pd.DataFrame(list(train_df['Descriptors']))[['MolWt', 'TPSA', 'NumRotatableBonds', 'NumHeavyAtoms']]\n",
    "test_descriptors = pd.DataFrame(list(test_df['Descriptors']))[['MolWt', 'TPSA', 'NumRotatableBonds', 'NumHeavyAtoms']]\n",
    "\n",
    "# Extract fingerprints\n",
    "train_fps = np.vstack(train_df['Descriptors'].apply(lambda x: x['Fingerprint']))\n",
    "test_fps = np.vstack(test_df['Descriptors'].apply(lambda x: x['Fingerprint']))\n",
    "\n",
    "# Combine features\n",
    "train_features = np.hstack([train_descriptors.values, train_fps])\n",
    "test_features = np.hstack([test_descriptors.values, test_fps])\n",
    "\n",
    "print('Train features shape:', train_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_descriptors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Correlation analysis\u001b[39;00m\n\u001b[0;32m      2\u001b[0m properties \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDensity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m corr_data \u001b[38;5;241m=\u001b[39m train_df[properties]\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mtrain_descriptors\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Correlation matrix\u001b[39;00m\n\u001b[0;32m      6\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m corr_data\u001b[38;5;241m.\u001b[39mcorr()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_descriptors' is not defined"
     ]
    }
   ],
   "source": [
    "# Correlation analysis\n",
    "properties = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "corr_data = train_df[properties].join(train_descriptors)\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = corr_data.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Descriptors and Properties')\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots\n",
    "for prop in properties:\n",
    "    for desc in ['MolWt', 'TPSA']:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.scatterplot(data=corr_data, x=desc, y=prop)\n",
    "        plt.title(f'{desc} vs {prop}')\n",
    "        plt.savefig(f'scatter_{desc}_vs_{prop}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for Tg\n",
      "No data for FFV\n",
      "No data for Tc\n",
      "No data for Density\n",
      "No data for Rg\n",
      "Model Report:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Model training and evaluation\n",
    "model_report = {}\n",
    "models = {}\n",
    "\n",
    "for prop in properties:\n",
    "    if train_df[prop].isna().all():\n",
    "        print(f'No data for {prop}')\n",
    "        continue\n",
    "    valid_data = train_df[train_df[prop].notna()]\n",
    "    X = np.vstack(valid_data['Descriptors'].apply(lambda x: np.hstack([list(x.values())[:-1], x['Fingerprint']])))\n",
    "    y = valid_data[prop]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    model_report[prop] = {'R2': r2, 'RMSE': rmse}\n",
    "    models[prop] = model\n",
    "    print(f'{prop} - R2: {r2:.3f}, RMSE: {rmse:.3f}')\n",
    "\n",
    "# Save model report\n",
    "report_df = pd.DataFrame(model_report).T\n",
    "report_df.to_csv('model_report.csv')\n",
    "print('Model Report:')\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file:\n",
      "Empty DataFrame\n",
      "Columns: [id, SMILES, Tg, FFV, Tc, Density, Rg]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Predictions for test SMILES\n",
    "predictions = {'id': test_df['id'], 'SMILES': test_df['SMILES']}\n",
    "for prop in properties:\n",
    "    if prop in models:\n",
    "        predictions[prop] = models[prop].predict(test_features)\n",
    "    else:\n",
    "        predictions[prop] = [np.nan] * len(test_df)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame(predictions)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print('Submission file:')\n",
    "print(submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Outputs\n",
    "- **Model Report**: `model_report.csv` with RÂ² and RMSE.\n",
    "- **Visualizations**: `correlation_matrix.png`, scatter plots (`scatter_{descriptor}_vs_{property}.png`).\n",
    "- **Submission**: `submission.csv` with predictions.\n",
    "\n",
    "To download, locate files in the working directory (or `/kaggle/working/` in Kaggle) and use the download option in Jupyter/Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
