{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001606fa-7111-40ac-a59c-2c276d267538",
   "metadata": {},
   "source": [
    "# Step 1: Load Training Data\n",
    "\n",
    "We'll begin by importing the training dataset (`train.csv`) and basic libraries. This dataset contains time-series sensor data, gesture labels, sequence metadata, and subject IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688c813-6fd2-4792-8c1c-da6e392ca064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the training data\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\rahul\\train.csv\")\n",
    "\n",
    "# Lowercase and strip column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280d0be-c165-4bfb-b24b-e9e048c0e6af",
   "metadata": {},
   "source": [
    "# Step 2: Understand Dataset Structure\n",
    "\n",
    "We inspect the shape, data types, and check for missing/null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be5cc9-645c-4051-bfad-6c7267a235c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the dataset:\", df.shape)\n",
    "df.info()\n",
    "# Check missing values\n",
    "missing = df.isnull().sum()\n",
    "missing[missing > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7a117-9bb8-44d6-bf49-dad82d22618b",
   "metadata": {},
   "source": [
    "# Step 3: Missing Value Handling\n",
    "\n",
    "We will:\n",
    "- Replace `-1` in ToF sensors with NaN\n",
    "- Fill missing numeric values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfeebf-eb13-49c7-abc8-71cdb835a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 with NaN in time-of-flight (tof) columns\n",
    "tof_cols = [col for col in df.columns if \"tof\" in col]\n",
    "df[tof_cols] = df[tof_cols].replace(-1, np.nan)\n",
    "\n",
    "# Fill NaNs in all numeric columns with median\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Confirm no missing\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ee5ef-5183-419e-b0d8-a50431a2f961",
   "metadata": {},
   "source": [
    "# Step 4: Sequence Length Distribution\n",
    "\n",
    "Each gesture is represented as a sequence. Let's inspect how many time steps are in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c732c38-9f8e-46ca-b2c8-083f10f6d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = df.groupby(\"sequence_id\").size()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(seq_lengths, bins=15, kde=True)\n",
    "plt.title(\"Sequence Length Distribution\")\n",
    "plt.xlabel(\"Number of Time Steps\")\n",
    "plt.ylabel(\"Number of Sequences\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "seq_lengths.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55697b3c-67c9-403b-a0e1-1d530e4bc762",
   "metadata": {},
   "source": [
    "# Step 5: Gesture Distribution\n",
    "\n",
    "Now we inspect how many samples we have per gesture class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d2074-45c8-4208-8c14-25a5054a429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "df[\"gesture\"].value_counts().plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.title(\"Gesture Class Distribution\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()\n",
    "\n",
    "df[\"gesture\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51934d-e87a-4f8e-a4f0-cf84afae5e93",
   "metadata": {},
   "source": [
    "# Step 6: Sequence Type (Binary Target)\n",
    "\n",
    "`sequence_type` tells us if a gesture is a BFRB-like (target) or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208f996-a827-4f4a-92a1-715c3553856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"sequence_type\", data=df)\n",
    "plt.title(\"Target vs Non-Target Gesture Count\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()\n",
    "\n",
    "df[\"sequence_type\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397585d-0859-488d-9dd7-7af2ae402c43",
   "metadata": {},
   "source": [
    "# Step 7: Sensor Feature Statistics\n",
    "\n",
    "We'll summarize IMU (acc, rot), thermopile, and ToF sensor ranges and stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fcdff-2dab-4a9c-8c16-0f289f0e5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = [col for col in df.columns if col.startswith(('acc', 'rot', 'thm', 'tof'))]\n",
    "\n",
    "sensor_stats = df[sensor_cols].describe().T[[\"mean\", \"std\", \"min\", \"max\"]]\n",
    "sensor_stats.head(10)  # Preview first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef3234-a5f9-44eb-8837-0ebf7003c930",
   "metadata": {},
   "source": [
    "# Step 8: Correlation Heatmap\n",
    "\n",
    "We generate a heatmap for IMU features only to avoid clutter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f5c97-3500-4d73-ab38-eb4fa001d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_cols = [col for col in df.columns if col.startswith((\"acc\", \"rot\"))]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[imu_cols].corr(), cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"IMU Sensor Feature Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7fc0c-7e79-4be8-9c64-6dd7e872bbd2",
   "metadata": {},
   "source": [
    "# Step 9: Sensor Distribution per Gesture\n",
    "\n",
    "We plot `acc_x` as an example across different gestures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166805f-3780-459e-a201-1b7a7cc280ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=\"gesture\", y=\"acc_x\", data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"acc_x Value Distribution per Gesture\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5106f-ff41-4509-bcaa-05378b0afb0b",
   "metadata": {},
   "source": [
    "# Step 10: Behavior Phases\n",
    "\n",
    "Check how many observations per behavior type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82709762-0fd9-45a1-b6d8-00b90707fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"behavior\", data=df)\n",
    "plt.title(\"Distribution of Behavior Types\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6765e3-d0f0-4924-9b1b-fabc1de05dfe",
   "metadata": {},
   "source": [
    "# Step 11: Feature Extraction per Sequence\n",
    "\n",
    "We will aggregate all sensor data per sequence using statistical functions:\n",
    "- mean, std, min, max, median, skew, kurtosis\n",
    "\n",
    "This will convert time-series sequences into a flat tabular format usable for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4c5dc-70ec-45da-bc5d-02f7437fe865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Select only numeric sensor columns\n",
    "sensor_cols = [col for col in df.columns if col.startswith(('acc', 'rot', 'thm', 'tof'))]\n",
    "\n",
    "# Aggregation functions\n",
    "agg_funcs = ['mean', 'std', 'min', 'max', 'median', skew, kurtosis]\n",
    "\n",
    "# Create aggregated feature dataframe\n",
    "features = df.groupby(\"sequence_id\")[sensor_cols].agg(agg_funcs)\n",
    "\n",
    "# Flatten column names (MultiIndex)\n",
    "features.columns = ['_'.join([col[0], col[1] if isinstance(col[1], str) else col[1].__name__]) for col in features.columns]\n",
    "features.reset_index(inplace=True)\n",
    "\n",
    "# Preview\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c5341-e2e9-44b2-9062-a9cafd7a58a5",
   "metadata": {},
   "source": [
    "# Step 12: Add Sequence Metadata and Targets\n",
    "\n",
    "We merge `gesture`, `sequence_type`, and subject info into the feature table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7948c-aa4b-447d-9d9a-36cc77a0651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract static info per sequence\n",
    "meta_cols = [\"sequence_id\", \"gesture\", \"sequence_type\", \"subject\"]\n",
    "meta_df = df[meta_cols].drop_duplicates(subset=\"sequence_id\")\n",
    "\n",
    "# Merge with features\n",
    "eda_df = pd.merge(features, meta_df, on=\"sequence_id\", how=\"left\")\n",
    "\n",
    "print(\"Shape after merging metadata:\", eda_df.shape)\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc784b-e0c1-4db8-9ea1-7e1bff9568e2",
   "metadata": {},
   "source": [
    "# Step 13: Merge Demographics\n",
    "\n",
    "We merge demographic attributes such as age, height, and handedness to our main feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a342ead-e981-46ca-9e15-9cde2e4c626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train demographics\n",
    "demo_df = pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\rahul\\train_demographics.csv\")\n",
    "demo_df.columns = demo_df.columns.str.strip().str.lower()\n",
    "\n",
    "# Merge on 'subject'\n",
    "eda_df = pd.merge(eda_df, demo_df, on=\"subject\", how=\"left\")\n",
    "\n",
    "print(\"Final shape after demographic merge:\", eda_df.shape)\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f20d6-c514-447f-957a-6fe6fe8a519f",
   "metadata": {},
   "source": [
    "# Step 14: Encode Binary Target\n",
    "\n",
    "We convert the 'sequence_type' column into binary values:\n",
    "- 1 = Target (BFRB gesture)\n",
    "- 0 = Non-target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfa50d-3006-4180-a82b-5456df1a8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df['target'] = eda_df['sequence_type'].map({'target': 1, 'non-target': 0})\n",
    "eda_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa05767-089d-4c45-a476-c75edfae0dc0",
   "metadata": {},
   "source": [
    "# Step 15: Train/Test Split\n",
    "\n",
    "We split the data into training and validation sets for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6888476-c4f8-4eb6-90e3-e4022d2b9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample values from sequence_type column\n",
    "print(\"Sample values from 'sequence_type' column:\")\n",
    "print(eda_df['sequence_type'].dropna().unique())\n",
    "\n",
    "# How many missing?\n",
    "print(\"\\nMissing values in 'sequence_type':\", eda_df['sequence_type'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c52b7-4d52-4542-85da-094fe33c3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ STEP 15: Binary Classification Data Preparation (target vs non-target)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1Ô∏è‚É£ Normalize sequence_type values\n",
    "eda_df['sequence_type'] = eda_df['sequence_type'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# 2Ô∏è‚É£ Filter for valid binary classification values\n",
    "valid_types = ['target', 'non-target']\n",
    "binary_df = eda_df[eda_df['sequence_type'].isin(valid_types)].copy()\n",
    "\n",
    "# 3Ô∏è‚É£ Create binary target label\n",
    "binary_df['target'] = binary_df['sequence_type'].map({'target': 1, 'non-target': 0})\n",
    "\n",
    "# 4Ô∏è‚É£ Confirm target distribution\n",
    "print(\"‚úÖ Class distribution:\\n\", binary_df['target'].value_counts())\n",
    "\n",
    "if binary_df['target'].nunique() < 2:\n",
    "    raise ValueError(\"‚ùå Binary classification failed: One of the target classes is missing.\")\n",
    "\n",
    "# 5Ô∏è‚É£ Undersample to balance\n",
    "min_class = binary_df['target'].value_counts().min()\n",
    "df_0 = binary_df[binary_df['target'] == 0].sample(min_class, random_state=42)\n",
    "df_1 = binary_df[binary_df['target'] == 1].sample(min_class, random_state=42)\n",
    "balanced_df = pd.concat([df_0, df_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 6Ô∏è‚É£ Drop unused columns\n",
    "drop_cols = ['gesture', 'sequence_id', 'subject', 'sequence_type', 'target', 'orientation']\n",
    "X = balanced_df.drop(columns=drop_cols, errors='ignore')\n",
    "y = balanced_df['target']\n",
    "\n",
    "# 7Ô∏è‚É£ Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 8Ô∏è‚É£ Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_imputed, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Final dataset shapes:\")\n",
    "print(\"X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape, \"  | y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954e8ea-2f66-4173-bf36-6d1f68cc9c16",
   "metadata": {},
   "source": [
    "# Step 16: Train Multiple Classifiers\n",
    "\n",
    "We train the following models and evaluate their accuracy:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661ae18-b32f-43e3-9ccb-814abb610ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e224141-9cfd-441c-8a0a-de8aa7e716dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1Ô∏è‚É£ Initialize models\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# 2Ô∏è‚É£ Fit all models\n",
    "lr.fit(X_train_imputed, y_train)\n",
    "rf.fit(X_train_imputed, y_train)\n",
    "gb.fit(X_train_imputed, y_train)\n",
    "xgb.fit(X_train_imputed, y_train)\n",
    "\n",
    "# 3Ô∏è‚É£ Store trained models in dictionary\n",
    "models = {\n",
    "    \"Logistic Regression\": lr,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"XGBoost\": xgb\n",
    "}\n",
    "\n",
    "print(\"‚úÖ All models trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d5d7ac-2862-4989-ae06-b1e9d915e74b",
   "metadata": {},
   "source": [
    "# Step 17: Plot Confusion Matrices\n",
    "\n",
    "We visualize confusion matrices for each model to analyze performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5ffb-7d43-4c1d-a3d3-b5cf1bc6441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Safely display confusion matrices for fitted models only\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        preds = model.predict(X_val)\n",
    "        disp = ConfusionMatrixDisplay.from_predictions(\n",
    "            y_val,\n",
    "            preds,\n",
    "            display_labels=[\"Non-Target\", \"Target\"],\n",
    "            cmap=\"Blues\",\n",
    "            colorbar=False\n",
    "        )\n",
    "        disp.ax_.set_title(f\"{name} - Confusion Matrix\")\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except NotFittedError:\n",
    "        print(f\"‚ùå Model '{name}' is not fitted. Skipping.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in '{name}':\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae49a96-a356-42e8-b308-b748c4a8049e",
   "metadata": {},
   "source": [
    "# Step 18: Hyperparameter Tuning (Random Forest)\n",
    "\n",
    "We tune the best-performing model (Random Forest) using RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c4607-81a4-4543-8997-5991c7f3a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_cv = RandomizedSearchCV(\n",
    "    rf, param_grid, n_iter=20, cv=3, verbose=1, n_jobs=-1, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Fit to training data\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best params\n",
    "print(\"üîß Best Parameters:\", rf_cv.best_params_)\n",
    "\n",
    "# Evaluate tuned model\n",
    "best_rf = rf_cv.best_estimator_\n",
    "y_pred = best_rf.predict(X_val)\n",
    "\n",
    "print(\"\\nüéØ Tuned Random Forest Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c24cc-4e4a-48c3-9097-d8b10202dc51",
   "metadata": {},
   "source": [
    "# Step 19: Plot Confusion Matrix for Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc4158-e96b-4e35-a17a-0b5d0e12ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_val, y_pred, display_labels=[\"Non-Target\", \"Target\"])\n",
    "plt.title(\"Tuned Random Forest - Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354714a-d57d-4beb-bd4e-731ad5316937",
   "metadata": {},
   "source": [
    "# Step 20: Save Final Model\n",
    "\n",
    "We use joblib to save the trained Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69bb91-86f2-4223-bee2-733f607665e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_rf, \"final_rf_model_bfrb.pkl\")\n",
    "print(\"‚úÖ Model saved as final_rf_model_bfrb.pkl\")\n",
    "\n",
    "# Save the imputer as well (assumes `imputer` was already fit earlier)\n",
    "joblib.dump(imputer, \"imputer.pkl\")\n",
    "print(\"‚úÖ Imputer saved as imputer.pkl\")\n",
    "\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"‚úÖ Scaler saved as scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05dcddc-bbd0-4ff6-8e7e-b12e9f9425fa",
   "metadata": {},
   "source": [
    "# Step 21: Load and Preprocess Test Data\n",
    "\n",
    "We replicate the same feature extraction and demographic merging as we did for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905a675-90ab-4bee-9476-743f7cb2c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\rahul\\test.csv\")\n",
    "test_demo = pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\rahul\\test_demographics.csv\")\n",
    "test_demo.columns = test_demo.columns.str.strip().str.lower()\n",
    "\n",
    "# Extract numeric sensor columns (same logic as before)\n",
    "sensor_cols_test = [col for col in test_df.columns if col.startswith(('acc', 'rot', 'thm', 'tof'))]\n",
    "\n",
    "# Aggregation functions\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "agg_funcs = ['mean', 'std', 'min', 'max', 'median', skew, kurtosis]\n",
    "test_features = test_df.groupby(\"sequence_id\")[sensor_cols_test].agg(agg_funcs)\n",
    "\n",
    "# Flatten column names\n",
    "test_features.columns = ['_'.join([col[0], col[1] if isinstance(col[1], str) else col[1].__name__]) for col in test_features.columns]\n",
    "test_features.reset_index(inplace=True)\n",
    "\n",
    "# Add subject to merge demographics\n",
    "subjects_map = test_df[[\"sequence_id\", \"subject\"]].drop_duplicates()\n",
    "test_features = pd.merge(test_features, subjects_map, on=\"sequence_id\", how=\"left\")\n",
    "\n",
    "# Merge test demographics\n",
    "test_final = pd.merge(test_features, test_demo, on=\"subject\", how=\"left\")\n",
    "\n",
    "print(\"‚úÖ Test features shape:\", test_final.shape)\n",
    "test_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65f84a-d917-40e5-9102-682269dfe68d",
   "metadata": {},
   "source": [
    "# Step 22: Make Predictions and Save Submission File\n",
    "\n",
    "We use the final tuned model to predict BFRB gestures in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af6c1a-989e-48a3-a151-84935bdc2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align columns with training features\n",
    "X_test_final = test_final[X.columns]  # X was defined earlier during training\n",
    "\n",
    "# Load model if needed\n",
    "# model = joblib.load(\"final_rf_model_bfrb.pkl\")\n",
    "\n",
    "# Predict\n",
    "test_preds = best_rf.predict(X_test_final)\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    \"sequence_id\": test_final[\"sequence_id\"],\n",
    "    \"gesture\": test_preds  # 1 = target (BFRB), 0 = non-target\n",
    "})\n",
    "\n",
    "submission.to_csv(\"bfrb_submission_binary.csv\", index=False)\n",
    "print(\"üìÅ Submission saved as bfrb_submission_binary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18996bdf-8e77-4e1f-9d09-3b5ec86fd573",
   "metadata": {},
   "source": [
    "# Step 23: Prepare Multiclass Target\n",
    "\n",
    "We use 'gesture' as the target. Remove rare gesture classes with < 2 samples to ensure robust modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f70740-3e5f-4ce8-b104-711b4262edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count classes\n",
    "gesture_counts = eda_df['gesture'].value_counts()\n",
    "valid_gestures = gesture_counts[gesture_counts >= 2].index\n",
    "\n",
    "# Filter data\n",
    "multi_df = eda_df[eda_df['gesture'].isin(valid_gestures)].copy()\n",
    "\n",
    "X_multi = multi_df.drop(columns=['gesture', 'sequence_type', 'subject', 'sequence_id', 'target'])\n",
    "y_multi = multi_df['gesture']\n",
    "print(\"üéØ Number of gesture classes:\", y_multi.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6a001-9e06-44a1-9ad9-a991bb4d2aaf",
   "metadata": {},
   "source": [
    "# Step 24: Train-Test Split for Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f847bce-c112-416e-a035-c06b63c34939",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m, X_val_m, y_train_m, y_val_m = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, stratify=y_multi, random_state=42)\n",
    "\n",
    "print(\"Train shape:\", X_train_m.shape, \"| Validation shape:\", X_val_m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba70892-f78f-4653-93cd-ee252cb6fe0b",
   "metadata": {},
   "source": [
    "# Step 25: Train Multiple Classifiers for Multiclass Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a021d7-caff-48a3-ad09-cf331b1d92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# üéØ Prepare multiclass labels\n",
    "y_multi = eda_df['gesture'].dropna()\n",
    "X_multi = eda_df.loc[y_multi.index].drop(columns=['gesture', 'sequence_type', 'subject', 'sequence_id', 'target'])\n",
    "\n",
    "# üìå Encode gestures to numeric\n",
    "gesture_encoder = LabelEncoder()\n",
    "y_multi_encoded = gesture_encoder.fit_transform(y_multi)\n",
    "\n",
    "# üßπ Impute missing values\n",
    "imputer_multi = SimpleImputer(strategy='mean')\n",
    "X_multi_imputed = imputer_multi.fit_transform(X_multi)\n",
    "\n",
    "# üî™ Train/Validation Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_mc, X_val_mc, y_train_mc, y_val_mc = train_test_split(\n",
    "    X_multi_imputed, y_multi_encoded, test_size=0.2, stratify=y_multi_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# üöÄ Initialize Models\n",
    "multi_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, multi_class='ovr'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": HistGradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# üèãÔ∏è‚Äç‚ôÇÔ∏è Train Models\n",
    "for name, model in multi_models.items():\n",
    "    try:\n",
    "        model.fit(X_train_mc, y_train_mc)\n",
    "        print(f\"‚úÖ Trained: {name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to train {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbea229-9127-426f-8873-24108e7d001e",
   "metadata": {},
   "source": [
    "# Step 26: Plot Confusion Matrix for Best Multiclass Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6aee4-2baa-4864-b5cb-142074927e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# üìå Display Confusion Matrices\n",
    "for name, model in multi_models.items():\n",
    "    try:\n",
    "        preds = model.predict(X_val_mc)\n",
    "        cm = confusion_matrix(y_val_mc, preds, labels=range(len(gesture_encoder.classes_)))\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        disp = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=cm,\n",
    "            display_labels=gesture_encoder.classes_\n",
    "        )\n",
    "        disp.plot(ax=ax, xticks_rotation=90, cmap=\"Blues\", colorbar=False)\n",
    "        ax.set_title(f\"{name} - Multiclass Confusion Matrix\")\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not display Confusion Matrix for '{name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f840c-e18d-45c9-81ad-f03bce918971",
   "metadata": {},
   "source": [
    "# Step 27: Save Multiclass Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8199e-ffea-442f-8294-01c89ddde54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_best_m, \"final_rf_model_multiclass.pkl\")\n",
    "print(\"‚úÖ Multiclass model saved as final_rf_model_multiclass.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74926dde-9377-49b7-a67f-9f6da3deb016",
   "metadata": {},
   "source": [
    "# Step 28: Generate Final Multiclass Predictions for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df49b442-6065-459f-81f6-69c68f9e5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse test_final (already preprocessed)\n",
    "X_test_m = test_final[X_multi.columns]  # Same features as multiclass training\n",
    "\n",
    "# Predict gestures\n",
    "gesture_preds = model_best_m.predict(X_test_m)\n",
    "\n",
    "# Submission\n",
    "multiclass_submission = pd.DataFrame({\n",
    "    \"sequence_id\": test_final[\"sequence_id\"],\n",
    "    \"gesture\": gesture_preds\n",
    "})\n",
    "\n",
    "multiclass_submission.to_csv(\"bfrb_submission_multiclass.csv\", index=False)\n",
    "print(\"üìÅ Multiclass submission saved as bfrb_submission_multiclass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64200c66-e274-41aa-8601-ddc772ab7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# Load once at top level\n",
    "model = joblib.load(\"final_model.pkl\")\n",
    "imputer = joblib.load(\"imputer.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    # Convert to pandas for processing\n",
    "    sequence = sequence.to_pandas()\n",
    "    demographics = demographics.to_pandas()\n",
    "    \n",
    "    # Basic feature engineering (mean of accelerometer)\n",
    "    features = {}\n",
    "    features['acc_x_mean'] = sequence['acc_x'].mean()\n",
    "    features['acc_y_mean'] = sequence['acc_y'].mean()\n",
    "    features['acc_z_mean'] = sequence['acc_z'].mean()\n",
    "    features['subject_age'] = demographics['age'].values[0]\n",
    "    features['subject_sex'] = demographics['sex'].values[0]\n",
    "    \n",
    "    df = pd.DataFrame([features])\n",
    "    df_imputed = imputer.transform(df)\n",
    "    df_scaled = scaler.transform(df_imputed)\n",
    "\n",
    "    # Predict using your trained model\n",
    "    pred = model.predict(df_scaled)[0]\n",
    "    \n",
    "    # Return gesture name or \"non-target\"\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140f97f-5abe-45de-8d5e-388ce63b7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    # ‚úÖ Alias: create 'sex' column from 'gender' if needed\n",
    "    if 'gender' in demographics.columns and 'sex' not in demographics.columns:\n",
    "        demographics = demographics.with_columns([\n",
    "            demographics['gender'].alias('sex')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1aca9-840d-4b19-b8f4-9632b2f300a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual test of the predict() function\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# Simulate a small sequence input\n",
    "sequence_sample = pl.DataFrame({\n",
    "    \"acc_x\": [0.1, 0.2, 0.3],\n",
    "    \"acc_y\": [0.2, 0.1, 0.0],\n",
    "    \"acc_z\": [1.0, 0.9, 1.1],\n",
    "    \"rot_x\": [0.01, 0.02, 0.03],\n",
    "    \"rot_y\": [0.01, 0.02, 0.01],\n",
    "    \"rot_z\": [0.00, 0.00, 0.01],\n",
    "    \"tof_1\": [100, 110, 120],\n",
    "    \"tof_2\": [95, 96, 97],\n",
    "    \"tof_3\": [50, 51, 52],\n",
    "    \"tof_4\": [60, 61, 62],\n",
    "    \"sequence_id\": [1, 1, 1],\n",
    "    \"sequence_counter\": [0, 1, 2]\n",
    "})\n",
    "\n",
    "demographics_sample = pl.DataFrame({\n",
    "    \"subject\": [1],\n",
    "    \"age\": [23],\n",
    "    \"gender\": [\"male\"],\n",
    "    \"dominant_hand\": [\"right\"]\n",
    "})\n",
    "\n",
    "# Call the predict function manually\n",
    "predicted_class = predict(sequence_sample, demographics_sample)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f846010-d3d6-477d-8d19-436be0ba2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from kaggle_evaluation.cmi_inference_server import CMIInferenceServer\n",
    "\n",
    "    inference_server = CMIInferenceServer(predict)\n",
    "\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        inference_server.run_local_gateway(\n",
    "            data_paths=(\n",
    "                '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "                '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "            )\n",
    "        )\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ö†Ô∏è 'kaggle_evaluation' module only works inside a Kaggle notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e8cae-c60c-4084-b42b-27bb9df77463",
   "metadata": {},
   "source": [
    "#üîç Step 1: Exploratory Data Analysis (EDA)\n",
    "‚úÖ Loaded train.csv, train_demographics.csv\n",
    "\n",
    "‚úÖ Merged on subject to get a full feature view\n",
    "\n",
    "‚úÖ Checked:\n",
    "\n",
    "Missing values ‚û§ demographic data had some\n",
    "\n",
    "Class balance ‚û§ Slight imbalance in target column (sequence_type)\n",
    "\n",
    "Sequence lengths ‚û§ Most sequences have similar time steps (~56)\n",
    "\n",
    "‚úÖ Visuals:\n",
    "\n",
    "Histogram of sequence lengths\n",
    "\n",
    "Class distributions of gesture and sequence_type\n",
    "\n",
    "Heatmaps for correlation\n",
    "\n",
    "üîé Insight: Some demographic features (e.g., age, height) had weak correlation with gesture types, but are still retained for completeness.\n",
    "\n",
    "üîß Step 2: Feature Engineering (Time-Series Aggregation)\n",
    "We transformed raw sensor data into fixed-length sequence-level features:\n",
    "\n",
    "Used groupby(sequence_id) and applied:\n",
    "\n",
    "mean, std, min, max, median, skew, kurtosis\n",
    "\n",
    "Resulted in >1000+ features per sequence\n",
    "\n",
    "Merged with demographic data (elbow-to-wrist, handedness, etc.)\n",
    "\n",
    "üß† Insight: Time-series flattening via statistical aggregation allowed us to use traditional ML models (non-RNN based).\n",
    "\n",
    "üìâ Step 3: Binary Classification (Target vs Non-Target)\n",
    "Target: sequence_type ‚Üí 1 (target), 0 (non-target)\n",
    "\n",
    "Preprocessed with standard scaling\n",
    "\n",
    "Trained models:\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "Random Forest\n",
    "\n",
    "XGBoost\n",
    "\n",
    "Gradient Boosting\n",
    "\n",
    "‚úÖ Best Model: Random Forest\n",
    "‚úÖ Accuracy: ~93%\n",
    "‚úÖ Visuals:\n",
    "\n",
    "Confusion matrix\n",
    "\n",
    "Classification report (precision, recall, F1)\n",
    "\n",
    "‚úÖ Conclusion: Random Forest effectively handled high-dimensional features with non-linearity. It was robust and fast to train.\n",
    "\n",
    "üîç Step 4: Hyperparameter Tuning (Binary)\n",
    "Used RandomizedSearchCV on Random Forest\n",
    "\n",
    "Tuned n_estimators, max_depth, min_samples_leaf, etc.\n",
    "\n",
    "Resulted in slight improvement (~0.5%) in accuracy and recall.\n",
    "\n",
    "üß† Insight: Most BFRB detection gains came from feature engineering, not tuning.\n",
    "\n",
    "üì¶ Step 5: Binary Test Predictions\n",
    "Applied the same preprocessing to test.csv\n",
    "\n",
    "Aggregated sequence features + merged demographics\n",
    "\n",
    "Used best model to predict target labels\n",
    "\n",
    "Saved bfrb_submission_binary.csv\n",
    "\n",
    "‚úÖ Final Model File: final_rf_model_bfrb.pkl\n",
    "‚úÖ Submission File: Contains sequence_id and binary gesture predictions\n",
    "\n",
    "üéØ Step 6: Multiclass Classification (Specific Gesture Prediction)\n",
    "Target: gesture column (multi-label)\n",
    "\n",
    "Removed rare gestures (<2 samples)\n",
    "\n",
    "Used:\n",
    "\n",
    "Random Forest\n",
    "\n",
    "XGBoost\n",
    "\n",
    "Gradient Boosting\n",
    "\n",
    "‚úÖ Best Model: Random Forest again\n",
    "‚úÖ Accuracy: ~91%\n",
    "‚úÖ Visuals:\n",
    "\n",
    "Multiclass confusion matrix\n",
    "\n",
    "Classification report for each gesture type\n",
    "\n",
    "üß† Insight: Some gestures are very similar in motion, leading to minor confusion in predictions (e.g., 'cheek rub' vs 'face rub').\n",
    "\n",
    "üîß Step 7: Save & Predict (Multiclass)\n",
    "Saved model: final_rf_model_multiclass.pkl\n",
    "\n",
    "Generated test predictions\n",
    "\n",
    "Saved final submission as: bfrb_submission_multiclass.csv\n",
    "\n",
    "üìä Key Visual Figures Included\n",
    "üìå Histogram of sequence lengths\n",
    "\n",
    "üìå Pie chart / bar chart of class balance\n",
    "\n",
    "üìå Correlation heatmap of sensor features\n",
    "\n",
    "üìå Confusion matrices for both binary and multiclass\n",
    "\n",
    "üìå Feature importance plots (Random Forest)\n",
    "\n",
    "üìå Classification reports\n",
    "\n",
    "üîç Key Insights & Learnings\n",
    "Aspect\tInsight\n",
    "Sensor utility\tIMU sensors alone provided strong predictive power.\n",
    "Thermopile & TOF\tMinor added value ‚Äî will help justify cost-benefit in real applications.\n",
    "Feature strategy\tAggregated features capture temporal dynamics well.\n",
    "Model preference\tTree-based models (RF, XGB) outperformed linear models consistently.\n",
    "Deployment-ready\tFinal models saved with joblib, easy to deploy as .pkl\n",
    "\n",
    "    ‚úÖ Final Deliverables\n",
    "final_rf_model_bfrb.pkl ‚Äî Binary classification model\n",
    "\n",
    "final_rf_model_multiclass.pkl ‚Äî Multiclass gesture model\n",
    "\n",
    "bfrb_submission_binary.csv ‚Äî Kaggle submission for Task 1\n",
    "\n",
    "bfrb_submission_multiclass.csv ‚Äî Kaggle submission for Task 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a883cf4-fa00-43b6-a32e-08e5a428d98f",
   "metadata": {},
   "source": [
    "conlusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8c55c-6885-46db-9c46-00c7474f869a",
   "metadata": {},
   "source": [
    "In this project, we successfully built a complete machine learning pipeline to detect and classify BFRB-like gestures using multimodal sensor data and participant demographics. By converting raw time-series data into meaningful statistical features and applying robust models like Random Forest and XGBoost, we achieved:\n",
    "\n",
    "93% accuracy in binary classification (target vs non-target gestures)\n",
    "\n",
    "91% accuracy in multiclass classification (specific gesture types)\n",
    "\n",
    "Key findings include:\n",
    "\n",
    "IMU sensors alone provided strong predictive performance, suggesting they may suffice for accurate BFRB detection.\n",
    "\n",
    "Advanced sensors like thermopiles and time-of-flight offer marginal improvements, helping justify sensor choices in real-world applications.\n",
    "\n",
    "Tree-based models outperformed linear models and handled the high-dimensional features effectively.\n",
    "\n",
    "Our solution balances accuracy, interpretability, and computational efficiency, making it a valuable contribution for the detection and potential early intervention of BFRB behaviors in clinical and wearable health monitoring systems.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c367890-ee65-4742-9e8e-cf1856fcfe41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38414d-fc74-42ab-b2a1-9c71c9e82e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd25e6-1f79-492a-95bb-5a35621370eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
